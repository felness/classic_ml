{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bieQL5lwfBD"
   },
   "source": [
    "# Прогнозируем задержки самолетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DARqocv0wz0z",
    "outputId": "6a67a371-88dc-4e02-8724-55b02e0e65f7"
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "U-gc09zSwvyF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C4LFGZPXweF2"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 111\n",
    "DATASET_PATH = 'https://raw.githubusercontent.com/evgpat/edu_stepik_practical_ml/main/datasets/flight_delays_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "m788vNOUxBNU",
    "outputId": "42974e99-32f3-45ff-fb4e-54c588d902e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732\n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834\n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416\n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872\n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "X = data.drop('dep_delayed_15min', axis=1)\n",
    "y = data['dep_delayed_15min'] == 'Y'\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoeAqm7x7Of9"
   },
   "source": [
    "Создайте список номеров колонок с категориальными признаками для бустингов\n",
    "\n",
    "## Quiz\n",
    "Какой длины получился список?\n",
    "\n",
    "(подсказка: колонка `DepTime` числовая)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "f2_RDMSdxgtC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cat_features = X.select_dtypes(include=object).columns.to_list()\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFUsTHb_7Tm0"
   },
   "source": [
    "Разобъем данные на обучение и контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "b5hPnUwvwu_Z"
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "EysJWEMy00fZ",
    "outputId": "ffdf59e5-f8b5-4c50-ac46-d52b0ef29503"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7534/3931462320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptuna\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "optuna --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E9ZC9UXymeu"
   },
   "source": [
    "## Модели с параметрами по умолчанию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiT-smHxypQx"
   },
   "source": [
    "Обучите CatBoost с гиперпараметрами по умолчанию.\n",
    "\n",
    "## Quiz\n",
    "Чему равен ROC-AUC на тестовых данных? Ответ округлите до сотых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "vdjpjT1Gw8ff"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02de741b736b4921a41c772832aff01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7679447117365583"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(logging_level='Silent')\n",
    "model.fit(Xtrain, ytrain,\n",
    "         cat_features=cat_features,\n",
    "         plot=True)\n",
    "pred = model.predict_proba(Xtest)[:,1]\n",
    "roc_auc = roc_auc_score(ytest, pred)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBO2HEaAy61O"
   },
   "source": [
    "Обучите LightGBM с гиперпараметрами по умолчанию.\n",
    "\n",
    "## Quiz\n",
    "Чему равен ROC-AUC на тестовых данных? Ответ округлите до сотых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "G_g3Ead3yZ5v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month            category\n",
       "DayofMonth       category\n",
       "DayOfWeek        category\n",
       "DepTime             int64\n",
       "UniqueCarrier    category\n",
       "Origin           category\n",
       "Dest             category\n",
       "Distance            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for c in X.columns:\n",
    "#     col_type = X[c].dtype\n",
    "#     if col_type == 'object' or col_type.name == 'category':\n",
    "#         Xtrain[c] = Xtrain[c].astype('category')\n",
    "#         Xtest[c] = Xtest[c].astype('category')\n",
    "for cols in X.columns:\n",
    "    if X[cols].dtypes == object:\n",
    "        Xtrain[cols] = Xtrain[cols].astype('category')\n",
    "        Xtest[cols] = Xtest[cols].astype('category')\n",
    "Xtrain.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Z2jPIID3xUPw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 14346, number of negative: 60654\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 75000, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.191280 -> initscore=-1.441714\n",
      "[LightGBM] [Info] Start training from score -1.441714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7341149074685321"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgmn = LGBMClassifier(\n",
    ")\n",
    "model_lgmn.fit(Xtrain, ytrain)\n",
    "pred = model_lgmn.predict_proba(Xtest)[:,1]\n",
    "roc_auc_score(ytest, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zazHv43vzn2e"
   },
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGaTMoDr7cvz"
   },
   "source": [
    "Выделим дополнительную валидационную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "meyw3CyV1aF_"
   },
   "outputs": [],
   "source": [
    "Xtrain_new, Xval, ytrain_new, yval = train_test_split(Xtrain, ytrain, test_size=0.25, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RatJBHjn1tq2"
   },
   "source": [
    "Создайте функцию objective_lgbm, в которой среди гиперпараметров\n",
    "\n",
    "* num_leaves = trial.suggest_int(\"num_leaves\", 10, 100)\n",
    "* n_estimators = trial.suggest_int(\"n_estimators\", 10, 1000)\n",
    "\n",
    "подберите оптимальные, обучая LGBM на Xtrain_new, ytrain_new и проверяя качество (ROC-AUC) на Xval.\n",
    "\n",
    "Используйте 30 эпох обучения Optuna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "YgOH1GMFzhW1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:23:58,354] A new study created in memory with name: no-name-1c80541c-c05e-4f68-82b5-3a52bfa41d9b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:24:25,449] Trial 0 finished with value: 0.716458523619676 and parameters: {'num_leaves': 19, 'n_estimators': 717}. Best is trial 0 with value: 0.716458523619676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:24:30,150] Trial 1 finished with value: 0.723209607740176 and parameters: {'num_leaves': 27, 'n_estimators': 132}. Best is trial 1 with value: 0.723209607740176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:25:07,617] Trial 2 finished with value: 0.7156014675974276 and parameters: {'num_leaves': 26, 'n_estimators': 867}. Best is trial 1 with value: 0.723209607740176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:25:09,819] Trial 3 finished with value: 0.7247959343434639 and parameters: {'num_leaves': 84, 'n_estimators': 20}. Best is trial 3 with value: 0.7247959343434639.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:25:14,837] Trial 4 finished with value: 0.7260980009262389 and parameters: {'num_leaves': 22, 'n_estimators': 121}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:26:18,746] Trial 5 finished with value: 0.719910959879355 and parameters: {'num_leaves': 90, 'n_estimators': 625}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:26:29,580] Trial 6 finished with value: 0.7205640489210837 and parameters: {'num_leaves': 11, 'n_estimators': 384}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:26:38,310] Trial 7 finished with value: 0.7201246482748216 and parameters: {'num_leaves': 62, 'n_estimators': 86}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:27:58,180] Trial 8 finished with value: 0.7181275918900302 and parameters: {'num_leaves': 96, 'n_estimators': 643}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:28:46,463] Trial 9 finished with value: 0.7192386838344418 and parameters: {'num_leaves': 70, 'n_estimators': 477}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:28:59,995] Trial 10 finished with value: 0.7180163072715597 and parameters: {'num_leaves': 45, 'n_estimators': 290}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:29:01,501] Trial 11 finished with value: 0.7242981960708527 and parameters: {'num_leaves': 45, 'n_estimators': 29}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:29:21,742] Trial 12 finished with value: 0.7200950089232356 and parameters: {'num_leaves': 79, 'n_estimators': 239}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:29:32,385] Trial 13 finished with value: 0.7225063401167857 and parameters: {'num_leaves': 50, 'n_estimators': 209}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:29:41,613] Trial 14 finished with value: 0.7242664278755799 and parameters: {'num_leaves': 83, 'n_estimators': 56}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:30:00,204] Trial 15 finished with value: 0.7202377236802558 and parameters: {'num_leaves': 35, 'n_estimators': 363}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:30:13,344] Trial 16 finished with value: 0.7205256018213693 and parameters: {'num_leaves': 65, 'n_estimators': 164}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:30:50,642] Trial 17 finished with value: 0.7185589157216185 and parameters: {'num_leaves': 57, 'n_estimators': 452}. Best is trial 4 with value: 0.7260980009262389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:30:54,930] Trial 18 finished with value: 0.7263426352168416 and parameters: {'num_leaves': 78, 'n_estimators': 28}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:31:36,290] Trial 19 finished with value: 0.7208265088513117 and parameters: {'num_leaves': 73, 'n_estimators': 326}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:31:42,382] Trial 20 finished with value: 0.7252067920383221 and parameters: {'num_leaves': 11, 'n_estimators': 191}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:31:47,016] Trial 21 finished with value: 0.725965281684211 and parameters: {'num_leaves': 11, 'n_estimators': 148}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:31:56,096] Trial 22 finished with value: 0.722780494982288 and parameters: {'num_leaves': 36, 'n_estimators': 127}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:32:07,229] Trial 23 finished with value: 0.7230363765114243 and parameters: {'num_leaves': 21, 'n_estimators': 253}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:32:13,633] Trial 24 finished with value: 0.724052264373368 and parameters: {'num_leaves': 34, 'n_estimators': 109}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:32:14,066] Trial 25 finished with value: 0.7202484227186982 and parameters: {'num_leaves': 17, 'n_estimators': 18}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:32:38,779] Trial 26 finished with value: 0.7170677932007985 and parameters: {'num_leaves': 10, 'n_estimators': 928}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:33:05,995] Trial 27 finished with value: 0.7189736839104589 and parameters: {'num_leaves': 26, 'n_estimators': 570}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:33:55,249] Trial 28 finished with value: 0.7182010141555495 and parameters: {'num_leaves': 96, 'n_estimators': 414}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 45520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 56250, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.190756 -> initscore=-1.445108\n",
      "[LightGBM] [Info] Start training from score -1.445108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-06 01:34:24,512] Trial 29 finished with value: 0.7160521794389004 and parameters: {'num_leaves': 21, 'n_estimators': 740}. Best is trial 18 with value: 0.7263426352168416.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def objective_lgbm(trial):\n",
    "    num_leaves = trial.suggest_int('num_leaves', 10, 100)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 1000)\n",
    "    model = LGBMClassifier(num_leaves=num_leaves, n_estimators=n_estimators, n_jobs=-1)\n",
    "    model.fit(Xtrain_new, ytrain_new)\n",
    "    pred = model.predict_proba(Xval)[:,1]\n",
    "    roc_auc = roc_auc_score(yval, pred)\n",
    "    return roc_auc\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_lgbm, n_trials=30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "fpPS4-E-2Ycm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 78, 'n_estimators': 28}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSWz4A5w7mpW"
   },
   "source": [
    "Обучите модель с найденными гиперпараметрами на Xtrain, ytrain и оцените ROC-AUC на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "C2i6MY720D1Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 14346, number of negative: 60654\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 75000, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.191280 -> initscore=-1.441714\n",
      "[LightGBM] [Info] Start training from score -1.441714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7333910096747289"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(n_estimators=28, num_leaves=78)\n",
    "model.fit(Xtrain, ytrain)\n",
    "pred = model.predict_proba(Xtest)[:,1]\n",
    "roc_auc_score(ytest, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bP4nfUCA5gnm"
   },
   "source": [
    "## Quiz\n",
    "\n",
    "Чему равно количество деревьев в LGBM после подбора гиперпараметров?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPVSkXK76b17"
   },
   "source": [
    "## Работа над улучшением модели\n",
    "\n",
    "* Попробуйте при помощи Optuna подобрать и другие гиперпарамтеры\n",
    "* Также подберите гиперпараметры у CatBoost (а не только у LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTjHyWL-6lm-"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kJk1Czm6nJg"
   },
   "source": [
    "## Quiz\n",
    "\n",
    "Поделитесь своими результатами!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
